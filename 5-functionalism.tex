\section{On Functionalism}
\label{sec:functionalism}

Georges Rey makes an important distinction between functionalist and behavioral theories of the mind. While behavioral theories only appeal to the input and output of the system, functionalist theories also consider the system's internal state. Rey claims that strong AI is a functionalist theory: a system that is not mediated by the right sort of program ``will not be regarded as satisfying some mental predicate, no matter how much its behavior may resemble the behavior of a system that does''~\cite[pp.~2-3]{rey1986s}.

Consequently, we can affirm that a program of behaving as if understanding Chinese is not necessarily also a program of understanding Chinese. On the other hand, the program of understanding Chinese is surely also a program of behaving as if understanding Chinese. We will refer to such programs as the \textit{Chinese behavior program} (CBP) and \textit{Chinese understanding program} (CUP).

We believe that, in the original Searle's Chinese room, what the person inside the room is simulating is the CBP: it contains the information to act as if understanding Chinese, but not necessarily the information to really understand Chinese. One could argue that this is a contradiction: the simulation of behaving in a certain way should not behave in a certain way no more than the simulation of flying should fly, and yet the Chinese room behaves correctly. However, we argue that in the case of the behavior of a program as in its input/output correlation, it is indeed simple, starting from the simulation of the program, to behave like the program: we just need to consider the inputs and outputs of the system as the inputs and outputs of the simulated program, which is exactly what the person inside the room is doing\footnote{This concludes the answer to question 1.}.

Even when the program inside the room is the CUP, we argue that understanding of Chinese is not achieved by the person. The problem is that ``the rules are still outside the person in the room: he has to look up the rules in a book''~\cite[p.~5]{rey1986s}. For the person in the room to understand Chinese, they would have to run the CUP directly on their brain. Using Harnad's terminology, the person is \textit{simulating} the program rather than \textit{implementing} the program. A person implements the CUP when that program runs directly on their brain\footnote{This concludes the answer to question 2.}.

However, we believe that a human has no way to directly run a program written on paper on their brain. When learning Chinese, we do not study the very program we aim to run in our brain but rather read from books that embellish raw rules with examples and connect new information with prior knowledge, which has been empirically proven to be effective in generating the execution of the correct program on the brain. If we were to be shown just the program, we would not be able to run it directly on our hardware as a computer does, because there is no reason for us to be able to do so\footnote{This concludes the answer to question 3.}.

Consequently, we can confidently claim that the person inside the room is incapable of doing anything other than simulating the program, which causes the person to be unable to understand, even in the case in which the program inside the room really is the CUP. However, this does not negate the fact that running the CUP on hardware does cause Chinese understanding, both in the case of the brain and – arguably – the computer.

Our claims until now assume the existence of the CUP, that is, the program that, when running on the brain, causes the understanding of Chinese. However, we argue that such a program may not exist. In fact, according to Rey, ``[t]o put Searle's example even in the running as a possible counterexample to Strong AI, we need to imagine the person in the room following rules that relate Chinese characters not only to one another but also to the inputs and outputs of (\ldots) other programs (\ldots) to account for the other mental processes of a normal Chinese speaker''~\cite[pp.~3-4]{rey1986s}.
If we consider the brain to be a collection of running programs, then the program(s)\footnote{Multiple programs may be needed to handle language as well.} in charge of the Chinese language may need to rely on other ones to cause the understanding of Chinese. As Rey explains, we ``no more need[] or ought to ascribe any understanding of Chinese to this latter part of the entire system than we need or ought to ascribe the properties of the entire British Empire to Queen Victoria''~\cite[p.6]{rey1986s}. The Chinese room thus also fails in addressing the possibly multi-program nature of the brain: even if a machine inside the room were to run the exact same program that is also run to handle language on the brain of a Chinese speaker, that machine would still not run the possible other programs necessary for intentionality.
