\section{General AI versus Strong AI}

When discussing the topic of strong AI, one needs to first define and distinguish the possible theoretical forms of machine intelligence clearly. It is often the case that the concept of strong AI is confused with that of general AI (AGI). The literature, however, shows that these two concepts are substantially different.

In \cite{goertzel2014artificial}, Ben Goertzel claims that, while the precise definition of general AI is vastly disputed within the AGI community, there is a broad agreement on some key ideas that characterize the concept. Therefore, general ``involves the ability to achieve a variety of goals, and carry out a variety of tasks, in a variety of different contexts and environments''. Moreover, ``the general intelligent system should be able to handle problems and situations quite different from those anticipated by its creators''~\cite[p.~2]{goertzel2014artificial}. Such a system can accomplish the above by generalizing the knowledge gained through experience, ``to transfer this knowledge from one problem or context to others''~\cite[p.~3]{goertzel2014artificial}. The concept of general AI is usually contra posed to that of narrow AI. Analogously, Kurzweil defines narrow AI in \cite{kurzweil2005singularity} as the creation of systems that carry out specific ``intelligent'' behaviors in specific contexts. Consequently, by changing ever so slightly the context or behavior specification of the system, some human reprogramming is needed for the system to retain its level of intelligence.

To provide an example, imagine a robot that is in charge of taking care of plants in a garden. The creators of such a robot might provide it with some prior information on the plants it will take care of, such as when to water them, or which compost to feed them. Let us now suppose that one day this robot is charged with taking care of a different, never seen before kind of plant that is not known by the creators. If the robot is endowed with general intelligence, it will be able to adapt to the new type of plant, perhaps by experimenting different treatments for the first few days, but also considering previous general knowledge such as ``when it is very sunny outside, the plant needs more water''. Moreover, the robot will gain additional knowledge when taking care of the new plants, which will be useful in the future. In contrast, a robot provided with a narrow type of intelligence, if not reprogrammed, would treat the new plants the same as the old ones, with detrimental effects on their health, and will gain no additional knowledge by doing so.

Of course, given the example above, it is evident that there exist several levels of general intelligence. Indeed, human intelligence can be considered more general than the intelligence of the robot in the example. Still, the AGI community believes that the general intelligence displayed by man is not the maximum expression of general intelligence~\cite{goertzel2014artificial}.

Strong AI is a term that has an established meaning in the AI and cognitive science literature. Searle defines a strong AI as an intelligent artificial machine that is able ``to understand and have other cognitive states''~\cite[p.~417]{searle1980minds}. Consequently, we can define a weak AI as an artificial machine that, although capable of displaying intelligent behavior, is not able to understand and have other cognitive states. Note that Searle uses the term ``cognitive states'' to refer to the states of the mind that allow for intentionality, that is, the ability of humans and animals to be conscious, be about things, represent things, and give meaning to representations.

General and strong AI are thus two very different concepts. Indeed, the human brain is an example of a system that is endowed with both strong and general intelligence. In the machine learning literature, the branch of meta learning attempts to develop a general intelligence by training neural models to easily adapt to multiple tasks~\cite{hospedales2020meta}; on the other hand, strong AI is not actively pursued. Finally, one could be tempted to say that a strong intelligence must also be at least as general as the intelligence displayed by humans or animals. However, we argue that this is not the case. In principle, there is nothing particularly absurd about the existence of a living being with a very narrow intelligence and ability to be intentional about things. However, we do concede that such a living being would probably need to be created artificially, as its inability to adapt to new conditions and tasks would be unfavorable in the context of natural selection. Therefore, we conclude that strong AI and general AI do not necessarily imply one another. In the following sections, we only consider strong AI, which is the subject of Searle's critique.
