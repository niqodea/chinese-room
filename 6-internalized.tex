\section{On the Internalized Chinese Room}

Various \textit{prima facie} counterarguments are addressed and rebutted by Searle himself in \cite{searle1980minds}. The most common rejoinder, the so-called ``system reply'', proposes the idea that it would be not the person inside the room themselves, but the system, to understand Chinese. In response to such an argument, Searle formulates another version of the thought experiment where the person in the room internalizes all the elements of the system. Because the person still does not understand anything of the Chinese stories, and the person is the system, Searle claims to prove the fallacy of the system reply. The conclusion is, according to Searle, not surprising, as it would be quite extraordinary for simple, inanimate elements of the Chinese room to be crucial for the existence of a mind. Though one cannot disprove that a priori, there is simply not enough evidence to believe that is the case.

Indeed, considering the ideas we have expressed so far, Searle's reply seems to be a menacing counterargument. If the person were to internalize the CUP, such a program would be stored in their brain. If the person inside the room were then to start running the program, we would conclude that the program is running directly on the brain, which should imply understanding: a contradiction.

However, we argue that there are two plausible ways to internalize the CUP inside the brain. In the first case, the program is \textit{run directly on} the brain and communicates with the other programs run on the brain fittingly. In this case, we believe that the person can indeed understand Chinese. Consequently, we argue that Searle's reply focuses on the second case, where the program is instead \textit{memorized on} the brain as a sequence of instructions. In this case, the brain does not \textit{run} the program, but rather, again, \textit{simulates} memorized operations by running a program that is equivalent to the program a modern computer runs to operate a virtual machine: while the behavior obtained might be the same on the surface, a simulation of the program, and not the actual program, is running on the hardware. Because simulations of understanding cannot understand, we can conclude that it is reasonable for the person to not understand Chinese. The contradiction mentioned above is thus only apparent. 
