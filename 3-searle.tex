\section{Searle's Argument}

Searle's argument in \cite{searle1980minds} is directed against the predominant philosophical positions of the strong AI community at the time, that is, the conviction that ``the appropriately programmed computer really is a mind, in the sense that computers given the right programs can be literally said to understand and have other cognitive states''. He refutes the above idea by claiming that: ``[i]nstantiating a computer program is never by itself a sufficient condition of intentionality''~\cite[p.~417]{searle1980minds}. The centerpiece of Searle's argument is the Chinese room thought experiment. 

\begin{itemize}
    \item Inside the Chinese room:
    \begin{enumerate}
        \item there is an English-speaking person, a book with a set of rules written in English, some empty sheets of papers, and two breaches on the walls, one for input and one for output;
        \item the person inside receives some sheets of paper with meaningless symbols from the input breach;
        \item the person can correlate one set of formal symbols with another set of formal symbols;
        \item the person applies the rules to fill other sheets of paper and provides them to the output breach.
    \end{enumerate}
    \item Outside the Chinese room:
    \begin{enumerate}
        \item stories and questions about the story in Chinese written on sheets of paper are entered in the room from the input breach;
        \item after some time, the appropriate answers in Chinese exit the room from the output breach.
    \end{enumerate}
\end{itemize}

Searle claims that, despite ultimately providing a correct answer as output, the person inside the room does not understand anything of the stories written in Chinese; in other words, the person does not have \textit{intentionality} of the content of the stories. He then observes that the person, by mindlessly following a program that processes Chinese scribbles, can be considered as analogous to a modern computer following the instructions given by a program. Because of this, he finally concludes that a computer cannot possibly cause intentionality, as the Chinese room argument shows that formal symbol manipulation – which is all the computer does – is not enough to produce cognitive states. Instead, one needs to consider the hardware running such programs before determining its ability to think. One cannot separate the program from the brain's hardware and call it a mind, because the brain's hardware contains something that is also crucial for the mind to exist.

The Chinese room argument has been the subject of numerous critiques, with some having gone as far as to define the field of cognitive science as the ongoing mission of demonstrating Searle's arguments wrong~\cite{lucas1982proceedings}. We describe, analyze, and build on some critiques that we believe are effective in questioning the validity of the above claims in sections \ref{sec:simulations} and \ref{sec:functionalism}.
