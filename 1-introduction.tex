\section{Introduction}

Searle in \cite{searle1980minds} argues that the biological matter of the human brain is essential for intentionality. The centerpiece of Searle's argument is a thought experiment, the Chinese room, where a person that follows the rules of a program answers to questions in Chinese without having intentionality of any of the Chinese utterances. The Chinese room has now been influencing the strong AI literature for decades. In this paper, we first define strong AI, distinguishing it from general AI, as the two terms are often confused with one another. Then, after a brief description of Searle's argument, we analyze and build upon some of the critiques advanced by Stevan Harnad in \cite{harnad1989minds} and Georges Rey in \cite{rey1986s} to challenge Searle's ideas. We find the Chinese room argument to be flawed when confronted with the concept of simulation and the ideas of functionalism; consequently, there is still no good reason to believe that a computer cannot attain consciousness. We attempt to thoroughly understand Searle's thought experiment and convincingly highlight its problems to hopefully help shift the focus of future strong AI research onto other (arguably more interesting) issues.
